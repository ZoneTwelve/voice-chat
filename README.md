# iRelate Voice Chat

A fully browser-based voice assistant. Speech recognition, LLM, and conversation all run locally in your browser - no API keys required for the core experience.

## What Makes This Different

**Everything runs in your browser:**
- **Speech-to-Text**: Whisper model running via WebGPU/WASM
- **Voice Activity Detection**: Silero VAD detects when you're speaking
- **LLM**: WebLLM loads Qwen/Llama directly into the browser
- **TTS**: Supertonic for natural speech output

No audio leaves your device. No API keys needed. Just open and talk.

## Quick Start

```bash
# Install dependencies
pnpm install

# Run development server
pnpm dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

First load downloads ~1GB of models (cached for future visits).

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Browser                              â”‚
â”‚                                                              â”‚
â”‚  ğŸ¤ Microphone                                               â”‚
â”‚       â†“                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Silero   â”‚ â†’ â”‚ Whisper  â”‚ â†’ â”‚ WebLLM   â”‚ â†’ â”‚Supertonicâ”‚  â”‚
â”‚  â”‚ VAD      â”‚   â”‚ STT      â”‚   â”‚ (Qwen)   â”‚   â”‚ TTS      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â†“              â†“              â†“              â†“        â”‚
â”‚  Detects      Transcribes     Generates       Speaks        â”‚
â”‚  speech       to text         response        response      â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## LLM Options

### Browser (Default)
WebLLM loads the model directly into your browser:
- Qwen 1.5B (default) - Good balance of quality and speed
- Qwen 0.5B - Faster, lighter
- Llama 1B/3B - Alternative models
- Gemma 2B, SmolLM - More options

### API Mode
For better responses, switch to API mode and use:
- OpenAI (GPT-4)
- Anthropic (Claude)
- Groq (fast inference)
- Ollama (local server)
- LM Studio (local server)

## Requirements

- Modern browser with WebGPU (Chrome 113+, Edge 113+)
- ~2GB RAM for models
- Microphone access

Falls back to WASM if WebGPU unavailable (slower but works).

## Environment Variables

Copy `.env.example` to `.env` and configure as needed:

```bash
# TTS server (required)
SUPERTONIC_URL=http://localhost:8000

# Optional: API keys for cloud LLMs
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GROQ_API_KEY=gsk_...
```

## Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx          # Main voice chat UI
â”‚   â”‚   â””â”€â”€ api/              # API routes for LLM/TTS
â”‚   â”œâ”€â”€ components/           # UI components
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ use-webllm.ts     # WebLLM integration
â”‚   â”‚   â””â”€â”€ use-tts.ts        # TTS integration
â”‚   â””â”€â”€ lib/                  # Utilities
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ stt-worker-esm.js     # Whisper + VAD worker
â”‚   â””â”€â”€ vad-processor.js      # Audio processor
â””â”€â”€ backend/                  # Optional Python backend
```

## Tech Stack

- **Framework**: Next.js 16, React 19
- **STT**: @huggingface/transformers (Whisper)
- **VAD**: Silero VAD via ONNX Runtime
- **LLM**: @mlc-ai/web-llm
- **TTS**: Supertonic
- **Styling**: Tailwind CSS

## Development

```bash
# Run with network access (test on other devices)
pnpm dev --hostname 0.0.0.0

# Production build
pnpm build
pnpm start
```

## License

MIT License - see [LICENSE](LICENSE)

## Credits

Built by [iRelate](https://irelate.ai)

- [Whisper](https://github.com/openai/whisper) - OpenAI
- [Silero VAD](https://github.com/snakers4/silero-vad) - snakers4
- [WebLLM](https://github.com/mlc-ai/web-llm) - MLC AI
- [Transformers.js](https://github.com/xenova/transformers.js) - Hugging Face
- Supertonic TTS
